{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8c70c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository cloned to: C:\\Users\\Soujanya\\Downloads\\PhonePe\n"
     ]
    }
   ],
   "source": [
    "from git import Repo\n",
    "\n",
    "def clone_github_repository(repo_url, clone_path):\n",
    "    repo = Repo.clone_from(repo_url, clone_path)\n",
    "    print(f\"Repository cloned to: {clone_path}\")\n",
    "    return repo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    owner = \"PhonePe\"\n",
    "    repo = \"pulse\"\n",
    "    repo_url = f\"https://github.com/{owner}/{repo}.git\"\n",
    "    clone_path = r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\"# Set the path where the repository will be cloned\n",
    "\n",
    "    clone_github_repository(repo_url, clone_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e791b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\aggregated\\user\\country\\india\\complete_aggregated_user.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_all_json_files(folder_path):\n",
    "    json_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                json_files.append(file_path)\n",
    "    return json_files\n",
    "\n",
    "def parse_json_file(file_path, state, year=None):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    data[\"state\"] = state\n",
    "    if year is not None:\n",
    "        data[\"year\"] = year\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clone_path = r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\aggregated\\user\\country\\india\"\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "    \n",
    "    json_files_list = []\n",
    "\n",
    "    # Fetch all state directories within the \"state\" subdirectory\n",
    "    state_directories = os.listdir(os.path.join(clone_path, \"state\"))\n",
    "\n",
    "    for state in state_directories:\n",
    "        state_path = os.path.join(clone_path, \"state\", state)\n",
    "        for year in years:\n",
    "            year_path = os.path.join(state_path, year)\n",
    "            json_files = find_all_json_files(year_path)\n",
    "            json_files_list.extend((file_path, state, year) for file_path in json_files)\n",
    "\n",
    "    all_data = []\n",
    "    for file_path, state, year in json_files_list:\n",
    "        parsed_data = parse_json_file(file_path, state, year)\n",
    "        all_data.append(parsed_data)\n",
    "\n",
    "    output_aggregated_file = os.path.join(clone_path, \"complete_aggregated_user.json\")\n",
    "    with open(output_aggregated_file, \"w\", encoding=\"utf-8\") as json_output:\n",
    "        json.dump(all_data, json_output, indent=4)\n",
    "\n",
    "    print(f\"Data saved to: {output_aggregated_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2a2a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\aggregated\\transaction\\country\\india\\complete_aggregated_trans.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_all_json_files(folder_path):\n",
    "    json_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                json_files.append(file_path)\n",
    "    return json_files\n",
    "\n",
    "def parse_json_file(file_path, state, year=None):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    data[\"state\"] = state\n",
    "    if year is not None:\n",
    "        data[\"year\"] = year\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clone_path = r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\aggregated\\transaction\\country\\india\"\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "    \n",
    "    json_files_list = []\n",
    "\n",
    "    # Fetch all state directories within the \"state\" subdirectory\n",
    "    state_directories = os.listdir(os.path.join(clone_path, \"state\"))\n",
    "\n",
    "    for state in state_directories:\n",
    "        state_path = os.path.join(clone_path, \"state\", state)\n",
    "        for year in years:\n",
    "            year_path = os.path.join(state_path, year)\n",
    "            json_files = find_all_json_files(year_path)\n",
    "            json_files_list.extend((file_path, state, year) for file_path in json_files)\n",
    "\n",
    "    all_data = []\n",
    "    for file_path, state, year in json_files_list:\n",
    "        parsed_data = parse_json_file(file_path, state, year)\n",
    "        all_data.append(parsed_data)\n",
    "\n",
    "    output_aggregated_file = os.path.join(clone_path, \"complete_aggregated_trans.json\")\n",
    "    with open(output_aggregated_file, \"w\", encoding=\"utf-8\") as json_output:\n",
    "        json.dump(all_data, json_output, indent=4)\n",
    "\n",
    "    print(f\"Data saved to: {output_aggregated_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a06c24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\map\\user\\hover\\country\\india\\complete_map_user.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_all_json_files(folder_path):\n",
    "    json_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                json_files.append(file_path)\n",
    "    return json_files\n",
    "\n",
    "def parse_json_file(file_path, state, year=None):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    data[\"state\"] = state\n",
    "    if year is not None:\n",
    "        data[\"year\"] = year\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clone_path = r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\map\\user\\hover\\country\\india\"\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "    \n",
    "    json_files_list = []\n",
    "\n",
    "    # Fetch all state directories within the \"state\" subdirectory\n",
    "    state_directories = os.listdir(os.path.join(clone_path, \"state\"))\n",
    "\n",
    "    for state in state_directories:\n",
    "        state_path = os.path.join(clone_path, \"state\", state)\n",
    "        for year in years:\n",
    "            year_path = os.path.join(state_path, year)\n",
    "            json_files = find_all_json_files(year_path)\n",
    "            json_files_list.extend((file_path, state, year) for file_path in json_files)\n",
    "\n",
    "    all_data = []\n",
    "    for file_path, state, year in json_files_list:\n",
    "        parsed_data = parse_json_file(file_path, state, year)\n",
    "        all_data.append(parsed_data)\n",
    "\n",
    "    output_map_file = os.path.join(clone_path, \"complete_map_user.json\")\n",
    "    with open(output_map_file, \"w\", encoding=\"utf-8\") as json_output:\n",
    "        json.dump(all_data, json_output, indent=4)\n",
    "\n",
    "    print(f\"Data saved to: {output_map_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0340452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\map\\transaction\\hover\\country\\india\\complete_map_trans.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_all_json_files(folder_path):\n",
    "    json_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                json_files.append(file_path)\n",
    "    return json_files\n",
    "\n",
    "def parse_json_file(file_path, state, year=None):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    data[\"state\"] = state\n",
    "    if year is not None:\n",
    "        data[\"year\"] = year\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clone_path = r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\map\\transaction\\hover\\country\\india\"\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "    \n",
    "    json_files_list = []\n",
    "\n",
    "    # Fetch all state directories within the \"state\" subdirectory\n",
    "    state_directories = os.listdir(os.path.join(clone_path, \"state\"))\n",
    "\n",
    "    for state in state_directories:\n",
    "        state_path = os.path.join(clone_path, \"state\", state)\n",
    "        for year in years:\n",
    "            year_path = os.path.join(state_path, year)\n",
    "            json_files = find_all_json_files(year_path)\n",
    "            json_files_list.extend((file_path, state, year) for file_path in json_files)\n",
    "\n",
    "    all_data = []\n",
    "    for file_path, state, year in json_files_list:\n",
    "        parsed_data = parse_json_file(file_path, state, year)\n",
    "        all_data.append(parsed_data)\n",
    "\n",
    "    output_map_file = os.path.join(clone_path, \"complete_map_trans.json\")\n",
    "    with open(output_map_file, \"w\", encoding=\"utf-8\") as json_output:\n",
    "        json.dump(all_data, json_output, indent=4)\n",
    "\n",
    "    print(f\"Data saved to: {output_map_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4f9df91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\top\\user\\country\\india\\complete_top_user.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_all_json_files(folder_path):\n",
    "    json_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                json_files.append(file_path)\n",
    "    return json_files\n",
    "\n",
    "def parse_json_file(file_path, state, year=None):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    data[\"state\"] = state\n",
    "    if year is not None:\n",
    "        data[\"year\"] = year\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clone_path = r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\top\\user\\country\\india\"\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "    \n",
    "    json_files_list = []\n",
    "\n",
    "    # Fetch all state directories within the \"state\" subdirectory\n",
    "    state_directories = os.listdir(os.path.join(clone_path, \"state\"))\n",
    "\n",
    "    for state in state_directories:\n",
    "        state_path = os.path.join(clone_path, \"state\", state)\n",
    "        for year in years:\n",
    "            year_path = os.path.join(state_path, year)\n",
    "            json_files = find_all_json_files(year_path)\n",
    "            json_files_list.extend((file_path, state, year) for file_path in json_files)\n",
    "\n",
    "    all_data = []\n",
    "    for file_path, state, year in json_files_list:\n",
    "        parsed_data = parse_json_file(file_path, state, year)\n",
    "        all_data.append(parsed_data)\n",
    "\n",
    "    output_top_file = os.path.join(clone_path, \"complete_top_user.json\")\n",
    "    with open(output_top_file, \"w\", encoding=\"utf-8\") as json_output:\n",
    "        json.dump(all_data, json_output, indent=4)\n",
    "\n",
    "    print(f\"Data saved to: {output_top_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67e804f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\top\\transaction\\country\\india\\complete_top_trans.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_all_json_files(folder_path):\n",
    "    json_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                json_files.append(file_path)\n",
    "    return json_files\n",
    "\n",
    "def parse_json_file(file_path, state, year=None):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    data[\"state\"] = state\n",
    "    if year is not None:\n",
    "        data[\"year\"] = year\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clone_path = r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\top\\transaction\\country\\india\"\n",
    "    years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]\n",
    "    \n",
    "    json_files_list = []\n",
    "\n",
    "    # Fetch all state directories within the \"state\" subdirectory\n",
    "    state_directories = os.listdir(os.path.join(clone_path, \"state\"))\n",
    "\n",
    "    for state in state_directories:\n",
    "        state_path = os.path.join(clone_path, \"state\", state)\n",
    "        for year in years:\n",
    "            year_path = os.path.join(state_path, year)\n",
    "            json_files = find_all_json_files(year_path)\n",
    "            json_files_list.extend((file_path, state, year) for file_path in json_files)\n",
    "\n",
    "    all_data = []\n",
    "    for file_path, state, year in json_files_list:\n",
    "        parsed_data = parse_json_file(file_path, state, year)\n",
    "        all_data.append(parsed_data)\n",
    "\n",
    "    output_top_file = os.path.join(clone_path, \"complete_top_trans.json\")\n",
    "    with open(output_top_file, \"w\", encoding=\"utf-8\") as json_output:\n",
    "        json.dump(all_data, json_output, indent=4)\n",
    "\n",
    "    print(f\"Data saved to: {output_top_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98998005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts DataFrame:\n",
      "       type     count        amount                      State  Year  \\\n",
      "0     TOTAL      5688  1.256025e+07  andaman-&-nicobar-islands  2018   \n",
      "1     TOTAL       528  1.139849e+06  andaman-&-nicobar-islands  2018   \n",
      "2     TOTAL       442  9.316631e+05  andaman-&-nicobar-islands  2018   \n",
      "3     TOTAL      9395  2.394824e+07  andaman-&-nicobar-islands  2018   \n",
      "4     TOTAL      1120  3.072437e+06  andaman-&-nicobar-islands  2018   \n",
      "...     ...       ...           ...                        ...   ...   \n",
      "5915  TOTAL  15651650  3.373698e+10                west-bengal  2022   \n",
      "5916  TOTAL  14484229  3.309949e+10                west-bengal  2022   \n",
      "5917  TOTAL  13931352  2.755409e+10                west-bengal  2022   \n",
      "5918  TOTAL  13350090  2.793786e+10                west-bengal  2022   \n",
      "5919  TOTAL  12768161  2.521681e+10                west-bengal  2022   \n",
      "\n",
      "                   Entity Name  \n",
      "0                     nicobars  \n",
      "1     north and middle andaman  \n",
      "2                south andaman  \n",
      "3                     nicobars  \n",
      "4     north and middle andaman  \n",
      "...                        ...  \n",
      "5915           purba medinipur  \n",
      "5916                   hooghly  \n",
      "5917                    howrah  \n",
      "5918         paschim medinipur  \n",
      "5919                       NaN  \n",
      "\n",
      "[5920 rows x 6 columns]\n",
      "\n",
      "Pincodes DataFrame:\n",
      "       type    count        amount                      State  Year  \\\n",
      "0     TOTAL     1622  2.769298e+06  andaman-&-nicobar-islands  2018   \n",
      "1     TOTAL     1223  2.238042e+06  andaman-&-nicobar-islands  2018   \n",
      "2     TOTAL      969  3.519060e+06  andaman-&-nicobar-islands  2018   \n",
      "3     TOTAL      685  1.298561e+06  andaman-&-nicobar-islands  2018   \n",
      "4     TOTAL      340  1.039715e+06  andaman-&-nicobar-islands  2018   \n",
      "...     ...      ...           ...                        ...   ...   \n",
      "7134  TOTAL  2900058  5.748321e+09                west-bengal  2022   \n",
      "7135  TOTAL  2471048  3.527457e+09                west-bengal  2022   \n",
      "7136  TOTAL  2407008  5.052109e+09                west-bengal  2022   \n",
      "7137  TOTAL  2348447  2.176640e+09                west-bengal  2022   \n",
      "7138  TOTAL  1765314  4.048329e+09                west-bengal  2022   \n",
      "\n",
      "     Entity Name  \n",
      "0         744103  \n",
      "1         744102  \n",
      "2         744105  \n",
      "3         744104  \n",
      "4         744107  \n",
      "...          ...  \n",
      "7134      700135  \n",
      "7135      732101  \n",
      "7136      700091  \n",
      "7137      711101  \n",
      "7138         NaN  \n",
      "\n",
      "[7139 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\aggregated\\transaction\\country\\india\\complete_aggregated_trans.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "districts_data_list = []\n",
    "pincodes_data_list = []\n",
    "\n",
    "# Iterate through each entry in the main list\n",
    "for entry in data_list:\n",
    "    districts_data = entry.get(\"data\", {}).get(\"districts\", [])\n",
    "    pincodes_data = entry.get(\"data\", {}).get(\"pincodes\", [])\n",
    "    state = entry.get(\"state\")\n",
    "    year = entry.get(\"year\")\n",
    "\n",
    "    for district in districts_data:\n",
    "        district_entity_name=district.get(\"entityName\")\n",
    "        district_data[\"Entity Name\"]=district_entity_name\n",
    "        district_data=district.get(\"metric\",{})\n",
    "        district_data[\"State\"] = state\n",
    "        district_data[\"Year\"] = year\n",
    "        districts_data_list.append(district_data)\n",
    "    \n",
    "    for pincode in pincodes_data:\n",
    "        pincode_entity_name=pincode.get(\"entityName\")\n",
    "        pincode_data[\"Entity Name\"]=pincode_entity_name\n",
    "        pincode_data=pincode.get(\"metric\",{})\n",
    "        pincode_data[\"State\"] = state\n",
    "        pincode_data[\"Year\"] = year\n",
    "        pincodes_data_list.append(pincode_data)\n",
    "\n",
    "# Create DataFrame for districts\n",
    "districts_df = pd.DataFrame(districts_data_list)\n",
    "\n",
    "# Create DataFrame for pincodes\n",
    "pincodes_df = pd.DataFrame(pincodes_data_list)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Districts DataFrame:\")\n",
    "print(districts_df)\n",
    "\n",
    "print(\"\\nPincodes DataFrame:\")\n",
    "print(pincodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e13ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts DataFrame:\n",
      "                     Entity Name                      State  Year   type  \\\n",
      "0                  south andaman  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "1                       nicobars  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "2       north and middle andaman  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "3                  south andaman  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "4                       nicobars  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "...                          ...                        ...   ...    ...   \n",
      "5915  south twenty four parganas                west-bengal  2022  TOTAL   \n",
      "5916             purba medinipur                west-bengal  2022  TOTAL   \n",
      "5917                     hooghly                west-bengal  2022  TOTAL   \n",
      "5918                      howrah                west-bengal  2022  TOTAL   \n",
      "5919           paschim medinipur                west-bengal  2022  TOTAL   \n",
      "\n",
      "         count        amount  \n",
      "0         5688  1.256025e+07  \n",
      "1          528  1.139849e+06  \n",
      "2          442  9.316631e+05  \n",
      "3         9395  2.394824e+07  \n",
      "4         1120  3.072437e+06  \n",
      "...        ...           ...  \n",
      "5915  15651650  3.373698e+10  \n",
      "5916  14484229  3.309949e+10  \n",
      "5917  13931352  2.755409e+10  \n",
      "5918  13350090  2.793786e+10  \n",
      "5919  12768161  2.521681e+10  \n",
      "\n",
      "[5920 rows x 6 columns]\n",
      "\n",
      "Pincodes DataFrame:\n",
      "     Pincode                      State  Year   type    count        amount\n",
      "0     744101  andaman-&-nicobar-islands  2018  TOTAL     1622  2.769298e+06\n",
      "1     744103  andaman-&-nicobar-islands  2018  TOTAL     1223  2.238042e+06\n",
      "2     744102  andaman-&-nicobar-islands  2018  TOTAL      969  3.519060e+06\n",
      "3     744105  andaman-&-nicobar-islands  2018  TOTAL      685  1.298561e+06\n",
      "4     744104  andaman-&-nicobar-islands  2018  TOTAL      340  1.039715e+06\n",
      "...      ...                        ...   ...    ...      ...           ...\n",
      "7134  722101                west-bengal  2022  TOTAL  2900058  5.748321e+09\n",
      "7135  700135                west-bengal  2022  TOTAL  2471048  3.527457e+09\n",
      "7136  732101                west-bengal  2022  TOTAL  2407008  5.052109e+09\n",
      "7137  700091                west-bengal  2022  TOTAL  2348447  2.176640e+09\n",
      "7138  711101                west-bengal  2022  TOTAL  1765314  4.048329e+09\n",
      "\n",
      "[7139 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\aggregated\\transaction\\country\\india\\complete_aggregated_trans.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "districts_data_list = []\n",
    "pincodes_data_list = []\n",
    "\n",
    "# Iterate through each entry in the main list\n",
    "for entry in data_list:\n",
    "    districts_data = entry.get(\"data\", {}).get(\"districts\", [])\n",
    "    pincodes_data = entry.get(\"data\", {}).get(\"pincodes\", [])\n",
    "    state = entry.get(\"state\")\n",
    "    year = entry.get(\"year\")\n",
    "\n",
    "    for district in districts_data:\n",
    "        district_entity_name = district.get(\"entityName\")\n",
    "        district_data = {\n",
    "            \"Entity Name\": district_entity_name,\n",
    "            \"State\": state,\n",
    "            \"Year\": year\n",
    "        }\n",
    "        district_data.update(district.get(\"metric\", {}))\n",
    "        districts_data_list.append(district_data)\n",
    "    \n",
    "    for pincode in pincodes_data:\n",
    "        pincode_entity_name = pincode.get(\"entityName\")\n",
    "        pincode_data = {\n",
    "            \"Pincode\": pincode_entity_name,\n",
    "            \"State\": state,\n",
    "            \"Year\": year\n",
    "        }\n",
    "        pincode_data.update(pincode.get(\"metric\", {}))\n",
    "        pincodes_data_list.append(pincode_data)\n",
    "\n",
    "# Create DataFrame for districts\n",
    "districts_df = pd.DataFrame(districts_data_list)\n",
    "\n",
    "# Create DataFrame for pincodes\n",
    "pincodes_df = pd.DataFrame(pincodes_data_list)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Districts DataFrame:\")\n",
    "print(districts_df)\n",
    "\n",
    "print(\"\\nPincodes DataFrame:\")\n",
    "print(pincodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "715fd61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HoverDataList DataFrame:\n",
      "        type     count        amount                        Entity Name  \\\n",
      "0      TOTAL       442  9.316631e+05  north and middle andaman district   \n",
      "1      TOTAL      5688  1.256025e+07             south andaman district   \n",
      "2      TOTAL       528  1.139849e+06                  nicobars district   \n",
      "3      TOTAL       825  1.317863e+06  north and middle andaman district   \n",
      "4      TOTAL      9395  2.394824e+07             south andaman district   \n",
      "...      ...       ...           ...                                ...   \n",
      "14631  TOTAL  12690126  2.804568e+10                     nadia district   \n",
      "14632  TOTAL   7617444  1.614650e+10                   birbhum district   \n",
      "14633  TOTAL  14484229  3.309949e+10           purba medinipur district   \n",
      "14634  TOTAL  12492746  2.721861e+10                    maldah district   \n",
      "14635  TOTAL   8827502  1.801650e+10                 darjiling district   \n",
      "\n",
      "                           State  Year  \n",
      "0      andaman-&-nicobar-islands  2018  \n",
      "1      andaman-&-nicobar-islands  2018  \n",
      "2      andaman-&-nicobar-islands  2018  \n",
      "3      andaman-&-nicobar-islands  2018  \n",
      "4      andaman-&-nicobar-islands  2018  \n",
      "...                          ...   ...  \n",
      "14631                west-bengal  2022  \n",
      "14632                west-bengal  2022  \n",
      "14633                west-bengal  2022  \n",
      "14634                west-bengal  2022  \n",
      "14635                west-bengal  2022  \n",
      "\n",
      "[14636 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\map\\transaction\\hover\\country\\india\\complete_map_trans.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "# Initialize a list to store extracted data\n",
    "hover_data_list = []\n",
    "\n",
    "# Iterate through each entry in the main list\n",
    "for entry in data_list:\n",
    "    hoverslist_data = entry.get(\"data\", {}).get(\"hoverDataList\", [])\n",
    "    state = entry.get(\"state\")\n",
    "    year = entry.get(\"year\")\n",
    "\n",
    "    for hover in hoverslist_data:\n",
    "        hover_entity_name = hover.get(\"name\")\n",
    "        hover_metric = hover.get(\"metric\", [{}])[0]\n",
    "        hover_metric[\"Entity Name\"] = hover_entity_name\n",
    "        hover_metric[\"State\"] = state\n",
    "        hover_metric[\"Year\"] = year\n",
    "        hover_data_list.append(hover_metric)\n",
    "\n",
    "# Create DataFrame for hover data\n",
    "hoversdatalist_df = pd.DataFrame(hover_data_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"HoverDataList DataFrame:\")\n",
    "print(hoversdatalist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "62ae7286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts DataFrame:\n",
      "                    DistrictName                      State  Year   type  \\\n",
      "0                  south andaman  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "1                       nicobars  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "2       north and middle andaman  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "3                  south andaman  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "4                       nicobars  andaman-&-nicobar-islands  2018  TOTAL   \n",
      "...                          ...                        ...   ...    ...   \n",
      "5915  south twenty four parganas                west-bengal  2022  TOTAL   \n",
      "5916             purba medinipur                west-bengal  2022  TOTAL   \n",
      "5917                     hooghly                west-bengal  2022  TOTAL   \n",
      "5918                      howrah                west-bengal  2022  TOTAL   \n",
      "5919           paschim medinipur                west-bengal  2022  TOTAL   \n",
      "\n",
      "         count        amount  \n",
      "0         5688  1.256025e+07  \n",
      "1          528  1.139849e+06  \n",
      "2          442  9.316631e+05  \n",
      "3         9395  2.394824e+07  \n",
      "4         1120  3.072437e+06  \n",
      "...        ...           ...  \n",
      "5915  15651650  3.373698e+10  \n",
      "5916  14484229  3.309949e+10  \n",
      "5917  13931352  2.755409e+10  \n",
      "5918  13350090  2.793786e+10  \n",
      "5919  12768161  2.521681e+10  \n",
      "\n",
      "[5920 rows x 6 columns]\n",
      "\n",
      "Pincodes DataFrame:\n",
      "     Pincode                      State  Year   type    count        amount\n",
      "0     744101  andaman-&-nicobar-islands  2018  TOTAL     1622  2.769298e+06\n",
      "1     744103  andaman-&-nicobar-islands  2018  TOTAL     1223  2.238042e+06\n",
      "2     744102  andaman-&-nicobar-islands  2018  TOTAL      969  3.519060e+06\n",
      "3     744105  andaman-&-nicobar-islands  2018  TOTAL      685  1.298561e+06\n",
      "4     744104  andaman-&-nicobar-islands  2018  TOTAL      340  1.039715e+06\n",
      "...      ...                        ...   ...    ...      ...           ...\n",
      "7134  722101                west-bengal  2022  TOTAL  2900058  5.748321e+09\n",
      "7135  700135                west-bengal  2022  TOTAL  2471048  3.527457e+09\n",
      "7136  732101                west-bengal  2022  TOTAL  2407008  5.052109e+09\n",
      "7137  700091                west-bengal  2022  TOTAL  2348447  2.176640e+09\n",
      "7138  711101                west-bengal  2022  TOTAL  1765314  4.048329e+09\n",
      "\n",
      "[7139 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\top\\transaction\\country\\india\\complete_top_trans.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "districts_data_list = []\n",
    "pincodes_data_list = []\n",
    "\n",
    "# Iterate through each entry in the main list\n",
    "for entry in data_list:\n",
    "    districts_data = entry.get(\"data\", {}).get(\"districts\", [])\n",
    "    pincodes_data = entry.get(\"data\", {}).get(\"pincodes\", [])\n",
    "    state = entry.get(\"state\")\n",
    "    year = entry.get(\"year\")\n",
    "\n",
    "    for district in districts_data:\n",
    "        district_entity_name = district.get(\"entityName\")\n",
    "        district_data = {\n",
    "            \"DistrictName\": district_entity_name,\n",
    "            \"State\": state,\n",
    "            \"Year\": year\n",
    "        }\n",
    "        district_data.update(district.get(\"metric\", {}))\n",
    "        districts_data_list.append(district_data)\n",
    "    \n",
    "    for pincode in pincodes_data:\n",
    "        pincode_entity_name = pincode.get(\"entityName\")\n",
    "        pincode_data = {\n",
    "            \"Pincode\": pincode_entity_name,\n",
    "            \"State\": state,\n",
    "            \"Year\": year\n",
    "        }\n",
    "        pincode_data.update(pincode.get(\"metric\", {}))\n",
    "        pincodes_data_list.append(pincode_data)\n",
    "\n",
    "# Create DataFrame for districts\n",
    "districtstoptrans_df = pd.DataFrame(districts_data_list)\n",
    "\n",
    "# Create DataFrame for pincodes\n",
    "pincodestoptrans_df = pd.DataFrame(pincodes_data_list)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Districts DataFrame:\")\n",
    "print(districtstoptrans_df)\n",
    "\n",
    "print(\"\\nPincodes DataFrame:\")\n",
    "print(pincodestoptrans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0fd65acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hover Data DataFrame:\n",
      "       registeredUsers  appOpens                        Entity Name  \\\n",
      "0                  632         0  north and middle andaman district   \n",
      "1                 5846         0             south andaman district   \n",
      "2                  262         0                  nicobars district   \n",
      "3                  911         0  north and middle andaman district   \n",
      "4                 8143         0             south andaman district   \n",
      "...                ...       ...                                ...   \n",
      "14635          1359420  33853990                     nadia district   \n",
      "14636           855236  20950662                   birbhum district   \n",
      "14637          1346908  38278506           purba medinipur district   \n",
      "14638           954892  29023743                    maldah district   \n",
      "14639           564562  15982631                 darjiling district   \n",
      "\n",
      "                           State  Year  \n",
      "0      andaman-&-nicobar-islands  2018  \n",
      "1      andaman-&-nicobar-islands  2018  \n",
      "2      andaman-&-nicobar-islands  2018  \n",
      "3      andaman-&-nicobar-islands  2018  \n",
      "4      andaman-&-nicobar-islands  2018  \n",
      "...                          ...   ...  \n",
      "14635                west-bengal  2022  \n",
      "14636                west-bengal  2022  \n",
      "14637                west-bengal  2022  \n",
      "14638                west-bengal  2022  \n",
      "14639                west-bengal  2022  \n",
      "\n",
      "[14640 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\map\\user\\hover\\country\\india\\complete_map_user.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "hover_data_list = []\n",
    "\n",
    "# Iterate through each entry in the main list\n",
    "for entry in data_list:\n",
    "    hover_data = entry.get(\"data\", {}).get(\"hoverData\", {})\n",
    "    state = entry.get(\"state\")\n",
    "    year = entry.get(\"year\")\n",
    "\n",
    "    for entity, entity_data in hover_data.items():\n",
    "        entity_data[\"Entity Name\"] = entity\n",
    "        entity_data[\"State\"] = state\n",
    "        entity_data[\"Year\"] = year\n",
    "        hover_data_list.append(entity_data)\n",
    "\n",
    "# Create DataFrame for hover data\n",
    "hover_df = pd.DataFrame(hover_data_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Hover Data DataFrame:\")\n",
    "print(hover_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a9f3006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts DataFrame:\n",
      "                      District  Registered Users                      State  \\\n",
      "0                south andaman              5846  andaman-&-nicobar-islands   \n",
      "1     north and middle andaman               632  andaman-&-nicobar-islands   \n",
      "2                     nicobars               262  andaman-&-nicobar-islands   \n",
      "3                south andaman              8143  andaman-&-nicobar-islands   \n",
      "4     north and middle andaman               911  andaman-&-nicobar-islands   \n",
      "...                        ...               ...                        ...   \n",
      "5915                    howrah           1422011                west-bengal   \n",
      "5916                     nadia           1359420                west-bengal   \n",
      "5917           purba medinipur           1346908                west-bengal   \n",
      "5918         paschim medinipur           1217113                west-bengal   \n",
      "5919           purba bardhaman           1119310                west-bengal   \n",
      "\n",
      "      Year  \n",
      "0     2018  \n",
      "1     2018  \n",
      "2     2018  \n",
      "3     2018  \n",
      "4     2018  \n",
      "...    ...  \n",
      "5915  2022  \n",
      "5916  2022  \n",
      "5917  2022  \n",
      "5918  2022  \n",
      "5919  2022  \n",
      "\n",
      "[5920 rows x 4 columns]\n",
      "\n",
      "Pincodes DataFrame:\n",
      "     Pincode  Registered Users                      State  Year\n",
      "0     744103              1608  andaman-&-nicobar-islands  2018\n",
      "1     744101              1108  andaman-&-nicobar-islands  2018\n",
      "2     744105              1075  andaman-&-nicobar-islands  2018\n",
      "3     744102              1006  andaman-&-nicobar-islands  2018\n",
      "4     744104               272  andaman-&-nicobar-islands  2018\n",
      "...      ...               ...                        ...   ...\n",
      "7135  700015            108457                west-bengal  2022\n",
      "7136  742304            105471                west-bengal  2022\n",
      "7137  721101            105279                west-bengal  2022\n",
      "7138  700091            102363                west-bengal  2022\n",
      "7139  700150            101966                west-bengal  2022\n",
      "\n",
      "[7140 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\top\\user\\country\\india\\complete_top_user.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "districts_data_list = []\n",
    "pincodes_data_list = []\n",
    "\n",
    "# Iterate through each entry in the main list\n",
    "for entry in data_list:\n",
    "    districts_data = entry.get(\"data\", {}).get(\"districts\", [])\n",
    "    pincodes_data = entry.get(\"data\", {}).get(\"pincodes\", [])\n",
    "    state = entry.get(\"state\")\n",
    "    year = entry.get(\"year\")\n",
    "\n",
    "    # Create DataFrame for districts\n",
    "    for district in districts_data:\n",
    "        district_name = district.get(\"name\")\n",
    "        district_registered_users = district.get(\"registeredUsers\")\n",
    "        districts_data_list.append({\n",
    "            \"District\": district_name,\n",
    "            \"Registered Users\": district_registered_users,\n",
    "            \"State\": state,\n",
    "            \"Year\": year\n",
    "        })\n",
    "\n",
    "    # Create DataFrame for pincodes\n",
    "    for pincode in pincodes_data:\n",
    "        pincode_name = pincode.get(\"name\")\n",
    "        pincode_registered_users = pincode.get(\"registeredUsers\")\n",
    "        pincodes_data_list.append({\n",
    "            \"Pincode\": pincode_name,\n",
    "            \"Registered Users\": pincode_registered_users,\n",
    "            \"State\": state,\n",
    "            \"Year\": year\n",
    "        })\n",
    "\n",
    "# Create DataFrame for districts\n",
    "districtstop_df = pd.DataFrame(districts_data_list)\n",
    "\n",
    "# Create DataFrame for pincodes\n",
    "pincodestop_df = pd.DataFrame(pincodes_data_list)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Districts DataFrame:\")\n",
    "print(districtstop_df)\n",
    "\n",
    "print(\"\\nPincodes DataFrame:\")\n",
    "print(pincodestop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f98b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated DataFrame:\n",
      "     Registered Users  App Opens                      State  Year\n",
      "0                6740          0  andaman-&-nicobar-islands  2018\n",
      "1                9405          0  andaman-&-nicobar-islands  2018\n",
      "2               12149          0  andaman-&-nicobar-islands  2018\n",
      "3               15222          0  andaman-&-nicobar-islands  2018\n",
      "4               18596          0  andaman-&-nicobar-islands  2019\n",
      "..                ...        ...                        ...   ...\n",
      "715          20644527  512335839                west-bengal  2021\n",
      "716          21919787  236131065                west-bengal  2022\n",
      "717          23124388  250276369                west-bengal  2022\n",
      "718          24372048  256445748                west-bengal  2022\n",
      "719          25536381  678066327                west-bengal  2022\n",
      "\n",
      "[720 rows x 4 columns]\n",
      "\n",
      "Users By Device DataFrame:\n",
      "        Brand    Count  Percentage                      State  Year\n",
      "0      Xiaomi     1665    0.247033  andaman-&-nicobar-islands  2018\n",
      "1     Samsung     1445    0.214392  andaman-&-nicobar-islands  2018\n",
      "2        Vivo      982    0.145697  andaman-&-nicobar-islands  2018\n",
      "3        Oppo      501    0.074332  andaman-&-nicobar-islands  2018\n",
      "4     OnePlus      332    0.049258  andaman-&-nicobar-islands  2018\n",
      "...       ...      ...         ...                        ...   ...\n",
      "6727   Lenovo   330017    0.015056                west-bengal  2022\n",
      "6728  Infinix   284678    0.012987                west-bengal  2022\n",
      "6729     Asus   280347    0.012790                west-bengal  2022\n",
      "6730    Apple   277752    0.012671                west-bengal  2022\n",
      "6731   Others  2196334    0.100199                west-bengal  2022\n",
      "\n",
      "[6732 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(r\"C:\\Users\\Soujanya\\Downloads\\PhonePe\\data\\aggregated\\user\\country\\india\\complete_aggregated_user.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "aggregated_data_list = []\n",
    "users_by_device_data_list = []\n",
    "\n",
    "# Iterate through each entry in the main list\n",
    "for entry in data_list:\n",
    "    aggregated_data = entry.get(\"data\", {}).get(\"aggregated\", {})\n",
    "    users_by_device_data = entry.get(\"data\", {}).get(\"usersByDevice\", [])\n",
    "    state = entry.get(\"state\")\n",
    "    year = entry.get(\"year\")\n",
    "\n",
    "    # Create DataFrame for aggregated data\n",
    "    aggregated_data_list.append({\n",
    "        \"Registered Users\": aggregated_data.get(\"registeredUsers\"),\n",
    "        \"App Opens\": aggregated_data.get(\"appOpens\"),\n",
    "        \"State\": state,\n",
    "        \"Year\": year\n",
    "    })\n",
    "\n",
    "    # Create DataFrame for usersByDevice data\n",
    "    if users_by_device_data is not None:\n",
    "        for device in users_by_device_data:\n",
    "            brand = device.get(\"brand\")\n",
    "            count = device.get(\"count\")\n",
    "            percentage = device.get(\"percentage\")\n",
    "            users_by_device_data_list.append({\n",
    "            \"Brand\": brand,\n",
    "            \"Count\": count,\n",
    "            \"Percentage\": percentage,\n",
    "            \"State\": state,\n",
    "            \"Year\": year\n",
    "        })\n",
    "\n",
    "# Create DataFrames\n",
    "aggregated_df = pd.DataFrame(aggregated_data_list)\n",
    "users_by_device_df = pd.DataFrame(users_by_device_data_list)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Aggregated DataFrame:\")\n",
    "print(aggregated_df)\n",
    "\n",
    "print(\"\\nUsers By Device DataFrame:\")\n",
    "print(users_by_device_df)\n",
    "\n",
    "aggregated_df.to_csv(\"cleaned_aggregated.csv\", index=False)\n",
    "users_by_device_df.to_csv(\"cleaned_users_by_device.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0f11723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed aggregated Dataframe:\n",
      "     Registered Users  App Opens                      State  Year\n",
      "0                6740          0  andaman-&-nicobar-islands  2018\n",
      "1                9405          0  andaman-&-nicobar-islands  2018\n",
      "2               12149          0  andaman-&-nicobar-islands  2018\n",
      "3               15222          0  andaman-&-nicobar-islands  2018\n",
      "4               18596          0  andaman-&-nicobar-islands  2019\n",
      "..                ...        ...                        ...   ...\n",
      "715          20644527  512335839                west-bengal  2021\n",
      "716          21919787  236131065                west-bengal  2022\n",
      "717          23124388  250276369                west-bengal  2022\n",
      "718          24372048  256445748                west-bengal  2022\n",
      "719          25536381  678066327                west-bengal  2022\n",
      "\n",
      "[720 rows x 4 columns]\n",
      "\n",
      "Processed Districts Dataframe:\n",
      "                      District  Registered Users                      State  \\\n",
      "0                south andaman              5846  andaman-&-nicobar-islands   \n",
      "1     north and middle andaman               632  andaman-&-nicobar-islands   \n",
      "2                     nicobars               262  andaman-&-nicobar-islands   \n",
      "3                south andaman              8143  andaman-&-nicobar-islands   \n",
      "4     north and middle andaman               911  andaman-&-nicobar-islands   \n",
      "...                        ...               ...                        ...   \n",
      "5915                    howrah           1422011                west-bengal   \n",
      "5916                     nadia           1359420                west-bengal   \n",
      "5917           purba medinipur           1346908                west-bengal   \n",
      "5918         paschim medinipur           1217113                west-bengal   \n",
      "5919           purba bardhaman           1119310                west-bengal   \n",
      "\n",
      "      Year  \n",
      "0     2018  \n",
      "1     2018  \n",
      "2     2018  \n",
      "3     2018  \n",
      "4     2018  \n",
      "...    ...  \n",
      "5915  2022  \n",
      "5916  2022  \n",
      "5917  2022  \n",
      "5918  2022  \n",
      "5919  2022  \n",
      "\n",
      "[5920 rows x 4 columns]\n",
      "\n",
      "Processed Pincodes Dataframe:\n",
      "     Pincode  Registered Users                      State  Year\n",
      "0     744103              1608  andaman-&-nicobar-islands  2018\n",
      "1     744101              1108  andaman-&-nicobar-islands  2018\n",
      "2     744105              1075  andaman-&-nicobar-islands  2018\n",
      "3     744102              1006  andaman-&-nicobar-islands  2018\n",
      "4     744104               272  andaman-&-nicobar-islands  2018\n",
      "...      ...               ...                        ...   ...\n",
      "7135  700015            108457                west-bengal  2022\n",
      "7136  742304            105471                west-bengal  2022\n",
      "7137  721101            105279                west-bengal  2022\n",
      "7138  700091            102363                west-bengal  2022\n",
      "7139  700150            101966                west-bengal  2022\n",
      "\n",
      "[7140 rows x 4 columns]\n",
      "\n",
      "Processed UsersByDevice Dataframe:\n",
      "        Brand    Count  Percentage                      State  Year\n",
      "0      Xiaomi     1665    0.247033  andaman-&-nicobar-islands  2018\n",
      "1     Samsung     1445    0.214392  andaman-&-nicobar-islands  2018\n",
      "2        Vivo      982    0.145697  andaman-&-nicobar-islands  2018\n",
      "3        Oppo      501    0.074332  andaman-&-nicobar-islands  2018\n",
      "4     OnePlus      332    0.049258  andaman-&-nicobar-islands  2018\n",
      "...       ...      ...         ...                        ...   ...\n",
      "6727   Lenovo   330017    0.015056                west-bengal  2022\n",
      "6728  Infinix   284678    0.012987                west-bengal  2022\n",
      "6729     Asus   280347    0.012790                west-bengal  2022\n",
      "6730    Apple   277752    0.012671                west-bengal  2022\n",
      "6731   Others  2196334    0.100199                west-bengal  2022\n",
      "\n",
      "[6732 rows x 5 columns]\n",
      "\n",
      "Processed Hover Dataframe:\n",
      "       registeredUsers  appOpens                        Entity Name  \\\n",
      "0                  632         0  north and middle andaman district   \n",
      "1                 5846         0             south andaman district   \n",
      "2                  262         0                  nicobars district   \n",
      "3                  911         0  north and middle andaman district   \n",
      "4                 8143         0             south andaman district   \n",
      "...                ...       ...                                ...   \n",
      "14635          1359420  33853990                     nadia district   \n",
      "14636           855236  20950662                   birbhum district   \n",
      "14637          1346908  38278506           purba medinipur district   \n",
      "14638           954892  29023743                    maldah district   \n",
      "14639           564562  15982631                 darjiling district   \n",
      "\n",
      "                           State  Year  \n",
      "0      andaman-&-nicobar-islands  2018  \n",
      "1      andaman-&-nicobar-islands  2018  \n",
      "2      andaman-&-nicobar-islands  2018  \n",
      "3      andaman-&-nicobar-islands  2018  \n",
      "4      andaman-&-nicobar-islands  2018  \n",
      "...                          ...   ...  \n",
      "14635                west-bengal  2022  \n",
      "14636                west-bengal  2022  \n",
      "14637                west-bengal  2022  \n",
      "14638                west-bengal  2022  \n",
      "14639                west-bengal  2022  \n",
      "\n",
      "[14640 rows x 5 columns]\n",
      "\n",
      "Processed HoverDataList Dataframe:\n",
      "        type     count        amount                        Entity Name  \\\n",
      "0      TOTAL       442  9.316631e+05  north and middle andaman district   \n",
      "1      TOTAL      5688  1.256025e+07             south andaman district   \n",
      "2      TOTAL       528  1.139849e+06                  nicobars district   \n",
      "3      TOTAL       825  1.317863e+06  north and middle andaman district   \n",
      "4      TOTAL      9395  2.394824e+07             south andaman district   \n",
      "...      ...       ...           ...                                ...   \n",
      "14631  TOTAL  12690126  2.804568e+10                     nadia district   \n",
      "14632  TOTAL   7617444  1.614650e+10                   birbhum district   \n",
      "14633  TOTAL  14484229  3.309949e+10           purba medinipur district   \n",
      "14634  TOTAL  12492746  2.721861e+10                    maldah district   \n",
      "14635  TOTAL   8827502  1.801650e+10                 darjiling district   \n",
      "\n",
      "                           State  Year  \n",
      "0      andaman-&-nicobar-islands  2018  \n",
      "1      andaman-&-nicobar-islands  2018  \n",
      "2      andaman-&-nicobar-islands  2018  \n",
      "3      andaman-&-nicobar-islands  2018  \n",
      "4      andaman-&-nicobar-islands  2018  \n",
      "...                          ...   ...  \n",
      "14631                west-bengal  2022  \n",
      "14632                west-bengal  2022  \n",
      "14633                west-bengal  2022  \n",
      "14634                west-bengal  2022  \n",
      "14635                west-bengal  2022  \n",
      "\n",
      "[14636 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "aggregated_df = pd.DataFrame(aggregated_df)\n",
    "districts_df = pd.DataFrame(districts_df)\n",
    "pincodes_df = pd.DataFrame(pincodes_df)\n",
    "users_by_device_df = pd.DataFrame(users_by_device_df)\n",
    "hover_df = pd.DataFrame(hover_df)\n",
    "hoversdatalist_df = pd.DataFrame(hoversdatalist_df)\n",
    "\n",
    "# 1. Handling Missing Values\n",
    "# Check for missing values and fill or drop them based on your analysis \n",
    "districts_df.fillna(0,inplace=True)\n",
    "pincodes_df.fillna(0,inplace=True)\n",
    "aggregated_df.fillna(0,inplace=True)\n",
    "users_by_device_df.fillna(0,inplace=True)\n",
    "hoversdatalist_df.fillna(0,inplace=True)\n",
    "hover_df.fillna(0,inplace=True)\n",
    "\n",
    "# Print the processed DataFrames\n",
    "print(\"Processed aggregated Dataframe:\")\n",
    "print(aggregated_df)\n",
    "\n",
    "print(\"\\nProcessed Districts Dataframe:\")\n",
    "print(districts_df)\n",
    "\n",
    "print(\"\\nProcessed Pincodes Dataframe:\")\n",
    "print(pincodes_df)\n",
    "\n",
    "print(\"\\nProcessed UsersByDevice Dataframe:\")\n",
    "print(users_by_device_df)\n",
    "\n",
    "print(\"\\nProcessed Hover Dataframe:\")\n",
    "print(hover_df)\n",
    "\n",
    "print(\"\\nProcessed HoverDataList Dataframe:\")\n",
    "print(hoversdatalist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da770c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.17)\n",
      "Requirement already satisfied: pymysql in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy) (4.6.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\soujanya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "efbdb575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into the MySQL tables.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "mysql_host = 'localhost'\n",
    "mysql_user = 'root'\n",
    "mysql_password = 'Ammu@2397'\n",
    "mysql_database = 'aggregatedf'\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(host=mysql_host, user=mysql_user, password=mysql_password, database=mysql_database)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables for the DataFrames\n",
    "aggregated_table_query = \"\"\"\n",
    "CREATE TABLE aggregated (\n",
    "    Registered Users INT,\n",
    "    App Opens BIGINT,\n",
    "    State VARCHAR(255),\n",
    "    Year INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "users_by_device_table_query = \"\"\"\n",
    "CREATE TABLE users_by_device (\n",
    "    Brand VARCHAR(255),\n",
    "    Count INT,\n",
    "    Percentage FLOAT,\n",
    "    State VARCHAR(255),\n",
    "    Year INT\n",
    ");\n",
    "\"\"\"\n",
    "aggregated_df = pd.DataFrame(aggregated_df)  \n",
    "user_by_device_df = pd.DataFrame(users_by_device_df)\n",
    "\n",
    "scaling_factor = 1000000  # Choose an appropriate scaling factor\n",
    "for index, row in aggregated_df.iterrows():\n",
    "    scaled_app_opens = int(row['App Opens'] / scaling_factor)  # Convert to integer after scaling\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO aggregated (RegisteredUsers, AppOpens, State, Year)\n",
    "        VALUES ({row['Registered Users']}, {scaled_app_opens}, '{row['State']}', {row['Year']})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "for index, row in users_by_device_df.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO users_by_device (Brand, Count, Percentage, State, Year)\n",
    "        VALUES ('{row['Brand']}', {row['Count']}, {row['Percentage']}, '{row['State']}', {row['Year']})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted into the MySQL tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f322eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into the MySQL tables.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "mysql_host = 'localhost'\n",
    "mysql_user = 'root'\n",
    "mysql_password = 'Ammu@2397'\n",
    "mysql_database = 'mapsdf'\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(host=mysql_host, user=mysql_user, password=mysql_password, database=mysql_database)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the hoverstable (if not already created)\n",
    "create_hoverstable_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hoverstable (\n",
    "        `Entity Name` VARCHAR(100),\n",
    "        `type` VARCHAR(100),\n",
    "        `count` BIGINT,\n",
    "        `amount` BIGINT,\n",
    "        `State` VARCHAR(255),\n",
    "        `Year` INT\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_hoverstable_query)\n",
    "conn.commit()\n",
    "\n",
    "# Create the hoversdatatable (if not already created)\n",
    "create_hoversdatatable_query = \"\"\"\n",
    "     CREATE TABLE IF NOT EXISTS hoversdatatable (\n",
    "         `registeredUsers` INT,\n",
    "         `appOpens` BIGINT,\n",
    "         `Entity Name` VARCHAR(100),\n",
    "         `State` VARCHAR(255),\n",
    "         `Year` INT\n",
    "     )\n",
    "\"\"\"\n",
    "cursor.execute(create_hoversdatatable_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert data into hoverstable\n",
    "for index, row in hoversdatalist_df.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO hoverstable (`Entity Name`, `type`, `count`, `amount`, `State`, `Year`)\n",
    "        VALUES ('{row['Entity Name']}', '{row['type']}', {row['count']}, {row['amount']}, '{row['State']}', {row['Year']})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Insert data into hoversdatatable\n",
    "scaling_factor = 1000000 \n",
    "for index, row in hover_df.iterrows():\n",
    "    scaled_app_opens = int(row['appOpens'] / scaling_factor)  # Convert to integer after scaling\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO hoversdatatable (`registeredUsers`, `appOpens`, `Entity Name`, `State`, `Year`)\n",
    "        VALUES ({row['registeredUsers']}, {scaled_app_opens}, '{row['Entity Name']}','{row['State']}', {row['Year']})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted into the MySQL tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e6639195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into the MySQL tables.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "mysql_host = 'localhost'\n",
    "mysql_user = 'root'\n",
    "mysql_password = 'Ammu@2397'\n",
    "mysql_database = 'aggregatedf'\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(host=mysql_host, user=mysql_user, password=mysql_password, database=mysql_database)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the districts_table (if not already created)\n",
    "create_districts_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS districts_table (\n",
    "        `Entity Name` VARCHAR(100),\n",
    "        `State` VARCHAR(100),\n",
    "        `Year` INT,\n",
    "        `type` Varchar(100),\n",
    "        `count` BIGINT,\n",
    "        `amount` BIGINT\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_districts_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Create the pincodes_table (if not already created)\n",
    "create_pincodes_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS pincodes_table (\n",
    "        `Pincode` BIGINT,\n",
    "        `State` VARCHAR(100),\n",
    "        `Year` INT,\n",
    "        `type` VARCHAR(100),\n",
    "        `count` BIGINT,\n",
    "        `amount` BIGINT\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_pincodes_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Assuming you have your DataFrame named districts_df and pincodes_df\n",
    "# Fill NaN values with 0\n",
    "districts_df = districts_df.fillna(0)\n",
    "pincodes_df = pincodes_df.fillna(0)\n",
    "\n",
    "# Insert data into districts_table\n",
    "for index, row in districts_df.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO districts_table (`Entity Name`, `State`, `Year`, `type`, `count`, `amount`)\n",
    "        VALUES ('{row[\"Entity Name\"]}', '{row[\"State\"]}', {row[\"Year\"]}, '{row[\"type\"]}', {row[\"count\"]}, {row[\"amount\"]})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Insert data into pincodes_table\n",
    "for index, row in pincodes_df.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO pincodes_table (`Pincode`, `State`, `Year`, `type`, `count`, `amount`)\n",
    "        VALUES ({row[\"Pincode\"]}, '{row[\"State\"]}', {row[\"Year\"]}, '{row[\"type\"]}', {row[\"count\"]}, {row[\"amount\"]})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted into the MySQL tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c06b4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into the MySQL tables.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "mysql_host = 'localhost'\n",
    "mysql_user = 'root'\n",
    "mysql_password = 'Ammu@2397'\n",
    "mysql_database = 'topdf'\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(host=mysql_host, user=mysql_user, password=mysql_password, database=mysql_database)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the districts_table (if not already created)\n",
    "create_districts_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS districts_table (\n",
    "        `District` VARCHAR(100),\n",
    "        `State` VARCHAR(100),\n",
    "        `Year` INT,\n",
    "        `Registered Users` INT\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_districts_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Create the pincodes_table (if not already created)\n",
    "create_pincodes_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS pincodes_table (\n",
    "        `Pincode` BIGINT,\n",
    "        `State` VARCHAR(100),\n",
    "        `Year` INT,\n",
    "        `Registered Users` INT\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_pincodes_table_query)\n",
    "conn.commit()\n",
    "\n",
    "create_userpincodes_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS userpincodes_table (\n",
    "        `Pincode` BIGINT,\n",
    "        `State` VARCHAR(100),\n",
    "        `Year` INT,\n",
    "        `type` VARCHAR(100),\n",
    "        `count` BIGINT,\n",
    "        `amount` BIGINT\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_userpincodes_table_query)\n",
    "conn.commit()\n",
    "\n",
    "create_userdistricts_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS userdistricts_table (\n",
    "        `DistrictName` VARCHAR(100),\n",
    "        `State` VARCHAR(100),\n",
    "        `Year` INT,\n",
    "        `type` VARCHAR(100),\n",
    "        `count` BIGINT,\n",
    "        `amount` BIGINT\n",
    "    )\n",
    "\"\"\"\n",
    "cursor.execute(create_userdistricts_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# Assuming you have your DataFrame named districts_df and pincodes_df\n",
    "# Fill NaN values with 0\n",
    "districtstop_df = districtstop_df.fillna(0)\n",
    "pincodestop_df = pincodestop_df.fillna(0)\n",
    "districtstoptrans_df = districtstoptrans_df.fillna(0)\n",
    "pincodestoptrans_df = pincodestoptrans_df.fillna(0)\n",
    "\n",
    "# Insert data into districts_table\n",
    "for index, row in districtstop_df.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO districts_table (`District`, `State`, `Year`, `Registered Users`)\n",
    "        VALUES ('{row[\"District\"]}', '{row[\"State\"]}', {row[\"Year\"]}, {row[\"Registered Users\"]})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Insert data into pincodes_table\n",
    "for index, row in pincodestop_df.iterrows():\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO pincodes_table (`Pincode`, `State`, `Year`, `Registered Users`)\n",
    "        VALUES ({row[\"Pincode\"]}, '{row[\"State\"]}', {row[\"Year\"]}, {row[\"Registered Users\"]})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "scaling_factor = 1000000\n",
    "for index,row in districtstoptrans_df.iterrows():\n",
    "    scaled_amount = int(row['amount'] / scaling_factor)  # Convert to integer after scaling\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO userdistricts_table (`DistrictName`, `State`, `Year`, `type`, `count`, `amount`)\n",
    "        VALUES ('{row[\"DistrictName\"]}', '{row[\"State\"]}', {row[\"Year\"]}, '{row[\"type\"]}', {row[\"count\"]}, {scaled_amount})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "scaling_factor = 1000000\n",
    "for index,row in pincodestoptrans_df.iterrows():\n",
    "    scaled_amount = int(row['amount'] / scaling_factor)\n",
    "    insert_query = f\"\"\"\n",
    "        INSERT INTO userpincodes_table (`Pincode`, `State`, `Year`, `type`, `count`, `amount`)\n",
    "        VALUES ({row[\"Pincode\"]}, '{row[\"State\"]}', {row[\"Year\"]}, '{row[\"type\"]}', {row[\"count\"]}, {scaled_amount})\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted into the MySQL tables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5a8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
